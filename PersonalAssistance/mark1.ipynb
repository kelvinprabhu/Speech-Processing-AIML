{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c53fd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: assistant_audio/command_1_Clear_male_voice.mp3 (Clear male voice)\n",
      "✅ Saved: assistant_audio/command_2_Clear_female_voice.mp3 (Clear female voice)\n",
      "✅ Saved: assistant_audio/command_3_Fast_speech.mp3 (Fast speech)\n",
      "✅ Saved: assistant_audio/command_4_Noisy_background.mp3 (Noisy background)\n",
      "✅ Saved: assistant_audio/command_5_Soft_voice.mp3 (Soft voice)\n",
      "✅ Saved: assistant_audio/command_6_Normal_voice.mp3 (Normal voice)\n",
      "\n",
      "All 6 commands converted to speech and saved in 'assistant_audio' folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: start: not found\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "def commands_to_speech_files(commands, output_dir=\"assistant_audio\", lang=\"en\"):\n",
    "    # Create output directory if not exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for i, (audio_type, command) in enumerate(commands, start=1):\n",
    "        filename = os.path.join(output_dir, f\"command_{i}_{audio_type.replace(' ', '_')}.mp3\")\n",
    "        tts = gTTS(text=command, lang=lang, slow=True)\n",
    "        tts.save(filename)\n",
    "        print(f\"✅ Saved: {filename} ({audio_type})\")\n",
    "\n",
    "    print(f\"\\nAll {len(commands)} commands converted to speech and saved in '{output_dir}' folder.\")\n",
    "\n",
    "    # Optional: Play the first file to confirm audio\n",
    "    try:\n",
    "        os.system(f\"start {os.path.join(output_dir, 'command_1_Clear_male_voice.mp3')}\")  # Windows\n",
    "    except:\n",
    "        os.system(f\"open {os.path.join(output_dir, 'command_1_Clear_male_voice.mp3')}\")  # macOS / Linux\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Each tuple = (Audio Type, Command)\n",
    "    commands = [\n",
    "        (\"Clear male voice\", \"Turn on the living room lights.\"),\n",
    "        (\"Clear female voice\", \"Set the thermostat to 22 degrees Celsius.\"),\n",
    "        (\"Fast speech\", \"Play my evening chill playlist.\"),\n",
    "        (\"Noisy background\", \"Lock the front door.\"),\n",
    "        (\"Soft voice\", \"What's the weather like today?\"),\n",
    "        (\"Normal voice\", \"Remind me to call mom at 6 PM.\"),\n",
    "    ]\n",
    "\n",
    "    commands_to_speech_files(commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdeadfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /mnt/a/MSAIM/trimister-5 msaiml/speech processing/Speech processing and recognisation/vosk/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /mnt/a/MSAIM/trimister-5 msaiml/speech processing/Speech processing and recognisation/vosk/vosk-model-small-en-us-0.15/graph/HCLr.fst /mnt/a/MSAIM/trimister-5 msaiml/speech processing/Speech processing and recognisation/vosk/vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /mnt/a/MSAIM/trimister-5 msaiml/speech processing/Speech processing and recognisation/vosk/vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: command_1_Clear_male_voice.mp3\n",
      "Recognizing with Whisper...\n",
      "Recognizing with Vosk...\n",
      "Speech successfully converted to text!\n",
      "Recognizing with Google Speech API...\n",
      "Speech successfully converted to text!\n",
      "\n",
      "--- Comparative Analysis ---\n",
      "Whisper Output: Whisper error: Failed to load audio: ffmpeg: error while loading shared libraries: libiconv.so.2: cannot open shared object file: No such file or directory\n",
      "\n",
      "Vosk Output: don't want the living room lights\n",
      "Google API Output: turn on the living room lights\n",
      "\n",
      "Processing file: command_2_Clear_female_voice.mp3\n",
      "Recognizing with Whisper...\n",
      "Recognizing with Vosk...\n",
      "Speech successfully converted to text!\n",
      "Recognizing with Google Speech API...\n",
      "Speech successfully converted to text!\n",
      "\n",
      "--- Comparative Analysis ---\n",
      "Whisper Output: Whisper error: Failed to load audio: ffmpeg: error while loading shared libraries: libiconv.so.2: cannot open shared object file: No such file or directory\n",
      "\n",
      "Vosk Output: set the thermostat to twenty two degrees celsius\n",
      "Google API Output: set the thermostat to 22 degree Celsius\n",
      "\n",
      "Processing file: command_3_Fast_speech.mp3\n",
      "Recognizing with Whisper...\n",
      "Recognizing with Vosk...\n",
      "Speech successfully converted to text!\n",
      "Recognizing with Google Speech API...\n",
      "Speech successfully converted to text!\n",
      "\n",
      "--- Comparative Analysis ---\n",
      "Whisper Output: Whisper error: Failed to load audio: ffmpeg: error while loading shared libraries: libiconv.so.2: cannot open shared object file: No such file or directory\n",
      "\n",
      "Vosk Output: play my evening chew playlist\n",
      "Google API Output: play my evening chill playlist\n",
      "\n",
      "Processing file: command_4_Noisy_background.mp3\n",
      "Recognizing with Whisper...\n",
      "Recognizing with Vosk...\n",
      "Speech successfully converted to text!\n",
      "Recognizing with Google Speech API...\n",
      "Speech successfully converted to text!\n",
      "\n",
      "--- Comparative Analysis ---\n",
      "Whisper Output: Whisper error: Failed to load audio: ffmpeg: error while loading shared libraries: libiconv.so.2: cannot open shared object file: No such file or directory\n",
      "\n",
      "Vosk Output: lock the front door\n",
      "Google API Output: lock the front door\n",
      "\n",
      "Processing file: command_5_Soft_voice.mp3\n",
      "Recognizing with Whisper...\n",
      "Recognizing with Vosk...\n",
      "Speech successfully converted to text!\n",
      "Recognizing with Google Speech API...\n",
      "Speech successfully converted to text!\n",
      "\n",
      "--- Comparative Analysis ---\n",
      "Whisper Output: Whisper error: Failed to load audio: ffmpeg: error while loading shared libraries: libiconv.so.2: cannot open shared object file: No such file or directory\n",
      "\n",
      "Vosk Output: what's the weather like today\n",
      "Google API Output: what's the weather like today\n",
      "\n",
      "Processing file: command_6_Normal_voice.mp3\n",
      "Recognizing with Whisper...\n",
      "Recognizing with Vosk...\n",
      "Speech successfully converted to text!\n",
      "Recognizing with Google Speech API...\n",
      "Speech successfully converted to text!\n",
      "\n",
      "--- Comparative Analysis ---\n",
      "Whisper Output: Whisper error: Failed to load audio: ffmpeg: error while loading shared libraries: libiconv.so.2: cannot open shared object file: No such file or directory\n",
      "\n",
      "Vosk Output: remind me to call mom at six pm\n",
      "Google API Output: remind me to call mum at 6:00 p.m.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io.wavfile import write as wavwrite\n",
    "import speech_recognition as sr\n",
    "import whisper\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "audio_folder = \"/mnt/a/MSAIM/trimister-5 msaiml/speech processing/Speech processing and recognisation/PersonalAssistance/assistant_audio\"\n",
    "vosk_model_path = os.path.join(audio_folder, \"/mnt/a/MSAIM/trimister-5 msaiml/speech processing/Speech processing and recognisation/vosk/vosk-model-small-en-us-0.15\")\n",
    "\n",
    "# Initialize models\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "vosk_model = Model(vosk_model_path)\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def mp3_to_wav_librosa(mp3_path, sr_target=16000):\n",
    "    \"\"\"Convert MP3 to WAV in memory and save temp file.\"\"\"\n",
    "    y, sr_orig = librosa.load(mp3_path, sr=sr_target)\n",
    "    wav_path = mp3_path.replace(\".mp3\", \"_temp.wav\")\n",
    "    wavwrite(wav_path, sr_target, (y * 32767).astype(np.int16))  # Convert float -> int16\n",
    "    return wav_path\n",
    "\n",
    "def transcribe_whisper(audio_path):\n",
    "    print(\"Recognizing with Whisper...\")\n",
    "    try:\n",
    "        result = whisper_model.transcribe(audio_path)\n",
    "        text = result.get(\"text\", \"\")\n",
    "        print(\"Speech successfully converted to text!\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Whisper error: {str(e)}\"\n",
    "\n",
    "def transcribe_vosk(audio_path):\n",
    "    print(\"Recognizing with Vosk...\")\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "        rec = KaldiRecognizer(vosk_model, 16000)\n",
    "        rec.AcceptWaveform(audio_data.get_raw_data())\n",
    "        result_json = json.loads(rec.Result())\n",
    "        text = result_json.get(\"text\", \"\")\n",
    "        print(\"Speech successfully converted to text!\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Vosk error: {str(e)}\"\n",
    "\n",
    "def transcribe_google(audio_path):\n",
    "    print(\"Recognizing with Google Speech API...\")\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(\"Speech successfully converted to text!\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Google Speech Recognition could not understand audio.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Google API unavailable: {e}\"\n",
    "\n",
    "# Process all MP3 files\n",
    "for file_name in os.listdir(audio_folder):\n",
    "    if file_name.endswith(\".mp3\"):\n",
    "        print(f\"\\nProcessing file: {file_name}\")\n",
    "        mp3_path = os.path.join(audio_folder, file_name)\n",
    "        \n",
    "        # Convert MP3 -> WAV without ffmpeg\n",
    "        wav_path = mp3_to_wav_librosa(mp3_path)\n",
    "        \n",
    "        whisper_text = transcribe_whisper(mp3_path)  # Whisper can read MP3 directly\n",
    "        vosk_text = transcribe_vosk(wav_path)\n",
    "        google_text = transcribe_google(wav_path)\n",
    "        \n",
    "        print(\"\\n--- Comparative Analysis ---\")\n",
    "        print(f\"Whisper Output: {whisper_text}\")\n",
    "        print(f\"Vosk Output: {vosk_text}\")\n",
    "        print(f\"Google API Output: {google_text}\")\n",
    "        \n",
    "        # Optional: delete temp WAV\n",
    "        os.remove(wav_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98d10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
