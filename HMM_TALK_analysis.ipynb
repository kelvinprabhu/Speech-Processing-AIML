{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. HMM Structural Analysis for the Word TALK (10 Marks)\n",
    "\n",
    "**The spoken word TALK is represented using a three state left to right Hidden Markov Model with phoneme states S1=/t/, S2=/ɔː/, and S3=/k/.**\n",
    "\n",
    "**a) Using your understanding of left to right HMM structures for single word pronunciation, explain why backward transitions such as P(/k/ to /t/) or P(/ɔː/ to /t/) must be zero. State the linguistic property of fixed phoneme ordering that this constraint enforces for the word TALK.**\n",
    "\n",
    "**b) The vowel state S2=/ɔː/ has a high self transition probability P(S2 to S2)=0.7, while the plosive state S1=/t/ has a low self transition probability P(S1 to S1)=0.1. Based on what you heard in the text to speech output, explain what these values imply about the relative duration of the phoneme /ɔː/ compared to the shorter burst like phoneme /t/ in the model.**\n",
    "\n",
    "**Date:** 2025-12-09\n",
    "\n",
    "This notebook implements a structural analysis of a three-state left-to-right Hidden Markov Model (HMM) for the spoken word **TALK** (/t/ /ɔː/ /k/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Set deterministic seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create figs directory if missing\n",
    "if not os.path.exists('./figs'):\n",
    "    os.makedirs('./figs')\n",
    "\n",
    "def save_show(fname):\n",
    "    \"\"\"Save the current figure to ./figs/ and show it.\"\"\"\n",
    "    plt.savefig(os.path.join('./figs', fname), bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Environment setup complete. Figures will be saved to ./figs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define HMM Topology and Parameters\n",
    "\n",
    "We define a **Left-to-Right (Bakis)** HMM topology. This structure is appropriate for modeling single words because speech is a temporal process where phonemes occur in a fixed sequence. In the word \"TALK\", the phoneme /t/ must precede /ɔː/, which must precede /k/. Backward transitions are disallowed to enforce this temporal order.\n",
    "\n",
    "**States:**\n",
    "- $S_1$: /t/ (Initial plosive)\n",
    "- $S_2$: /ɔː/ (Vowel)\n",
    "- $S_3$: /k/ (Final plosive)\n",
    "\n",
    "**Transition Matrix ($A$):**\n",
    "We use the following probabilities:\n",
    "- $S_1 \\to S_1$: 0.1 (Short duration)\n",
    "- $S_1 \\to S_2$: 0.9\n",
    "- $S_2 \\to S_2$: 0.7 (Longer duration)\n",
    "- $S_2 \\to S_3$: 0.3\n",
    "- $S_3 \\to S_3$: 1.0 (Absorbing state representing the end of the word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define states\n",
    "states = [\"t\", \"ɔː\", \"k\"]\n",
    "n_states = len(states)\n",
    "\n",
    "# Define Transition Matrix A\n",
    "# Rows sum to 1.0\n",
    "A = np.array([\n",
    "    [0.1, 0.9, 0.0],\n",
    "    [0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "# Define Emission Models (Conceptual parameters for synthetic generation later)\n",
    "# Format: State -> {mean, sigma}\n",
    "emissions = {\n",
    "    0: {'mean': 0.0, 'sigma': 1.5, 'desc': '/t/ burst'},\n",
    "    1: {'mean': 3.0, 'sigma': 0.5, 'desc': '/ɔː/ sustained'},\n",
    "    2: {'mean': 0.5, 'sigma': 1.0, 'desc': '/k/ release'}\n",
    "}\n",
    "\n",
    "def plot_topology(A, states):\n",
    "    \"\"\"Draws the HMM topology as a directed graph.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for i, state in enumerate(states):\n",
    "        G.add_node(i, label=state)\n",
    "    \n",
    "    # Add edges with probabilities\n",
    "    rows, cols = A.shape\n",
    "    edge_labels = {}\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if A[i, j] > 0:\n",
    "                G.add_edge(i, j)\n",
    "                edge_labels[(i, j)] = f\"{A[i, j]:.2f}\"\n",
    "    \n",
    "    pos = {0: (0, 0), 1: (1, 0), 2: (2, 0)}  # Linear layout\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    nx.draw(G, pos, with_labels=True, labels={i: s for i, s in enumerate(states)},\n",
    "            node_size=3000, node_color='lightblue', font_size=12, font_weight='bold',\n",
    "            arrowsize=20, edge_color='gray')\n",
    "    \n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')\n",
    "    plt.title(\"HMM Topology: Left-to-Right Model for 'TALK'\")\n",
    "    save_show(\"topology.png\")\n",
    "\n",
    "plot_topology(A, states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Task 1(a)\n",
    "**Why backward transitions must be zero:**\n",
    "Backward transitions (e.g., $P(/k/ \\to /t/)$ or $P(/ɔː/ \\to /t/)$) must be zero to strictly enforce the **temporal order** of the phonemes. Speech is a causal, time-forward process. In the word \"TALK\", the sound /t/ always precedes /ɔː/, which always precedes /k/. Allowing backward transitions would imply the possibility of the sequence reversing (e.g., \"TA-K-O\"), which is linguistically impossible for a single utterance of this specific word.\n",
    "\n",
    "**Linguistic Property:**\n",
    "This constraint enforces the linguistic property of **fixed phoneme ordering** (or temporal sequencing). The Left-to-Right topology mathematically encodes the fact that words are sequences of phonemes that unfold linearly in time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Transition Matrix\n",
    "\n",
    "We will visualize the transition matrix $A$ as a heatmap to inspect the allowed transitions and their probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transition_matrix(A, states):\n",
    "    \"\"\"Plots the transition matrix as a heatmap.\"\"\"\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(A, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=states, yticklabels=states, cbar=False)\n",
    "    plt.title(\"Transition Matrix A\")\n",
    "    plt.xlabel(\"To State\")\n",
    "    plt.ylabel(\"From State\")\n",
    "    save_show(\"transition_matrix.png\")\n",
    "\n",
    "plot_transition_matrix(A, states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The heatmap highlights the structure of the matrix:\n",
    "- **Upper-triangular nature**: The zeros in the lower triangle (e.g., /ɔː/ $\\to$ /t/) confirm that backward transitions are impossible.\n",
    "- **Diagonal**: Represents the probability of staying in the current state (self-transition).\n",
    "- **Off-diagonal**: Represents the probability of moving to the next phoneme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Expected State Duration (Analytic)\n",
    "\n",
    "In a discrete-time HMM, the number of time steps (frames) a system stays in a state $i$ with self-transition probability $a_{ii}$ follows a geometric distribution.\n",
    "\n",
    "The expected duration $E[d_i]$ is given by:\n",
    "$$ E[d_i] = \\frac{1}{1 - a_{ii}} $$\n",
    "\n",
    "- For $S_1$ (/t/): $a_{11} = 0.1$\n",
    "- For $S_2$ (/ɔː/): $a_{22} = 0.7$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_durations(A, states):\n",
    "    \"\"\"Computes and plots expected durations for non-absorbing states.\"\"\"\n",
    "    durations = {}\n",
    "    for i in range(len(states) - 1): # Skip last state (absorbing)\n",
    "        p_self = A[i, i]\n",
    "        expected_d = 1.0 / (1.0 - p_self)\n",
    "        durations[states[i]] = expected_d\n",
    "        \n",
    "    # Create DataFrame\n",
    "    df_dur = pd.DataFrame(list(durations.items()), columns=['State', 'Expected Duration (frames)'])\n",
    "    print(df_dur)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x='State', y='Expected Duration (frames)', data=df_dur, palette='viridis')\n",
    "    plt.title(\"Analytic Expected Durations\")\n",
    "    for index, row in df_dur.iterrows():\n",
    "        plt.text(index, row['Expected Duration (frames)'] + 0.1, \n",
    "                 f\"{row['Expected Duration (frames)']:.2f}\", ha='center')\n",
    "    save_show(\"expected_durations.png\")\n",
    "    return df_dur\n",
    "\n",
    "df_analytic = compute_expected_durations(A, states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Task 1(b)\n",
    "**Implications of $p_{self}$ values on relative duration:**\n",
    "The self-transition probability $p_{self}$ determines the expected dwell time in a state.\n",
    "- A low $p_{self} = 0.1$ for /t/ results in a short expected duration:\n",
    "  $$ E[d_{/t/}] = \\frac{1}{1 - 0.1} \\approx 1.11 \\text{ frames} $$\n",
    "  This matches the acoustic property of a **plosive burst**, which is a very short, transient event.\n",
    "- A high $p_{self} = 0.7$ for /ɔː/ results in a significantly longer expected duration:\n",
    "  $$ E[d_{/ɔː/}] = \\frac{1}{1 - 0.7} \\approx 3.33 \\text{ frames} $$\n",
    "  This matches the acoustic property of a **sustained vowel**, which is held for a longer period of time.\n",
    "\n",
    "Thus, the model parameters ($0.1$ vs $0.7$) correctly reflect that the vowel /ɔː/ has a much longer relative duration than the short burst-like phoneme /t/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate Sequences (Monte Carlo)\n",
    "\n",
    "We will simulate 5,000 utterances using the defined HMM to empirically validate the expected durations. We start at $S_1$ and sample transitions until we reach the absorbing state $S_3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hmm(A, n_trials=5000):\n",
    "    \"\"\"Simulates HMM sequences and records dwell times.\"\"\"\n",
    "    dwell_times = {0: [], 1: []} # Record for S1 and S2\n",
    "    \n",
    "    for _ in range(n_trials):\n",
    "        state = 0\n",
    "        current_dwell = 0\n",
    "        \n",
    "        # We simulate until we hit the absorbing state S3 (index 2)\n",
    "        # Max steps safety break\n",
    "        for t in range(100): \n",
    "            current_dwell += 1\n",
    "            \n",
    "            # Sample next state\n",
    "            next_state = np.random.choice(len(A), p=A[state])\n",
    "            \n",
    "            if next_state != state:\n",
    "                # State change\n",
    "                if state in dwell_times:\n",
    "                    dwell_times[state].append(current_dwell)\n",
    "                state = next_state\n",
    "                current_dwell = 0\n",
    "            \n",
    "            if state == 2: # Absorbing state /k/\n",
    "                break\n",
    "                \n",
    "    return dwell_times\n",
    "\n",
    "dwell_times = simulate_hmm(A)\n",
    "\n",
    "# Calculate empirical means\n",
    "empirical_means = {s: np.mean(times) for s, times in dwell_times.items()}\n",
    "print(\"Empirical Means:\", empirical_means)\n",
    "\n",
    "# Plot Histograms\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(dwell_times[0], bins=range(1, 10), alpha=0.7, label='/t/ (S1)', density=True, align='left')\n",
    "plt.hist(dwell_times[1], bins=range(1, 20), alpha=0.7, label='/ɔː/ (S2)', density=True, align='left')\n",
    "plt.title(\"Distribution of Dwell Times (Empirical)\")\n",
    "plt.xlabel(\"Duration (frames)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "save_show(\"dwell_histograms.png\")\n",
    "\n",
    "# Comparison Plot\n",
    "states_subset = [\"t\", \"ɔː\"]\n",
    "analytic_vals = [df_analytic.iloc[0]['Expected Duration (frames)'], df_analytic.iloc[1]['Expected Duration (frames)']]\n",
    "empirical_vals = [empirical_means[0], empirical_means[1]]\n",
    "\n",
    "x = np.arange(len(states_subset))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(x - width/2, analytic_vals, width, label='Analytic')\n",
    "plt.bar(x + width/2, empirical_vals, width, label='Empirical')\n",
    "plt.xticks(x, states_subset)\n",
    "plt.ylabel('Duration (frames)')\n",
    "plt.title('Empirical vs Theoretical Mean Duration')\n",
    "plt.legend()\n",
    "save_show(\"empirical_vs_theory.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The empirical results closely match the theoretical expectations. The histograms show the geometric distribution shape (exponential decay in discrete time). Small deviations are due to sampling noise, which decreases as the number of trials increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Synthetic Waveform Generation\n",
    "\n",
    "We generate a \"toy\" acoustic signal to visualize the difference between the short burst of /t/ and the sustained vowel /ɔː/.\n",
    "- **/t/**: Modeled as high-variance noise (burst).\n",
    "- **/ɔː/**: Modeled as a sine wave (periodic).\n",
    "- **/k/**: Modeled as a short silence followed by a burst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_waveform(A, emissions):\n",
    "    \"\"\"Generates a synthetic waveform for one utterance.\"\"\"\n",
    "    state = 0\n",
    "    waveform = []\n",
    "    state_seq = []\n",
    "    \n",
    "    # Generate sequence\n",
    "    while state != 2:\n",
    "        state_seq.append(state)\n",
    "        # Generate 100 samples per frame (arbitrary sampling rate)\n",
    "        n_samples = 100 \n",
    "        t_vec = np.linspace(0, 1, n_samples)\n",
    "        \n",
    "        if state == 0: # /t/ - Noise burst\n",
    "            chunk = np.random.normal(0, 1, n_samples) * emissions[0]['sigma']\n",
    "        elif state == 1: # /ɔː/ - Sine wave\n",
    "            chunk = np.sin(2 * np.pi * 5 * t_vec) * emissions[1]['mean'] + np.random.normal(0, 0.1, n_samples)\n",
    "        \n",
    "        waveform.extend(chunk)\n",
    "        state = np.random.choice(len(A), p=A[state])\n",
    "        \n",
    "    # Add final /k/ (State 2)\n",
    "    # /k/ is closure (silence) + release (burst)\n",
    "    # We'll simulate 1 frame of /k/\n",
    "    state_seq.append(2)\n",
    "    closure = np.zeros(50)\n",
    "    release = np.random.normal(0, 1, 50) * emissions[2]['sigma']\n",
    "    waveform.extend(np.concatenate([closure, release]))\n",
    "    \n",
    "    return np.array(waveform), state_seq\n",
    "\n",
    "# Generate and Plot\n",
    "wave, seq = generate_synthetic_waveform(A, emissions)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(wave)\n",
    "plt.title(f\"Synthetic Waveform for 'TALK' (Sequence: {seq})\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "save_show(\"synthetic_waveform.png\")\n",
    "\n",
    "# Spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.specgram(wave, NFFT=128, Fs=1000, noverlap=64)\n",
    "plt.title(\"Synthetic Spectrogram\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Time\")\n",
    "save_show(\"synthetic_spectrogram.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The waveform and spectrogram visually demonstrate the linguistic structure:\n",
    "- The initial segment (random noise) corresponds to the /t/ burst.\n",
    "- The middle segment (periodic signal) corresponds to the /ɔː/ vowel, which is longer and has a clear frequency structure.\n",
    "- The final segment represents the /k/ release.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook has successfully implemented a structural analysis of the HMM for the word \"TALK\".\n",
    "\n",
    "**Summary of Findings:**\n",
    "1.  **Topology:** The Left-to-Right topology with zero backward transitions is essential for modeling the fixed temporal sequence of phonemes in a word.\n",
    "2.  **Durations:** The self-transition probabilities ($p_{self}$) directly control the expected duration of each state. A high $p_{self}$ (0.7) correctly models the sustained nature of the vowel /ɔː/, while a low $p_{self}$ (0.1) models the transient nature of the plosive /t/.\n",
    "3.  **Simulation:** Monte Carlo simulations confirmed that the empirical dwell times match the theoretical geometric distributions derived from the transition matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run\n",
    "Ensure you have `numpy`, `matplotlib`, `seaborn`, `pandas`, `networkx`, and `scipy` installed. Run the notebook cell-by-cell.\n",
    "\n",
    "### References\n",
    "- Rabiner, L. R. (1989). \"A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition\". Proceedings of the IEEE.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
